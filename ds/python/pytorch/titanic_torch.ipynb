{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.drop(['PassengerId','Name', 'Ticket', 'Cabin', 'Embarked'], axis=1, inplace=True)\n",
    "df=pd.get_dummies(df) #one-hot encoding 방식으로 펼쳐주니까 col개수 증가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass   Age  SibSp  Parch     Fare  Sex_female  Sex_male\n",
       "0         0.0     3.0  22.0    1.0    0.0   7.2500         0.0       1.0\n",
       "1         1.0     1.0  38.0    1.0    0.0  71.2833         1.0       0.0\n",
       "2         1.0     3.0  26.0    0.0    0.0   7.9250         1.0       0.0\n",
       "3         1.0     1.0  35.0    1.0    0.0  53.1000         1.0       0.0\n",
       "4         0.0     3.0  35.0    0.0    0.0   8.0500         0.0       1.0\n",
       "..        ...     ...   ...    ...    ...      ...         ...       ...\n",
       "886       0.0     2.0  27.0    0.0    0.0  13.0000         0.0       1.0\n",
       "887       1.0     1.0  19.0    0.0    0.0  30.0000         1.0       0.0\n",
       "888       0.0     3.0  26.8    1.0    2.0  23.4500         1.0       0.0\n",
       "889       1.0     1.0  26.0    0.0    0.0  30.0000         0.0       1.0\n",
       "890       0.0     3.0  32.0    0.0    0.0   7.7500         0.0       1.0\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "imputed = imputer.fit_transform(df)\n",
    "df_imputed=pd.DataFrame(imputed, columns = df.columns)\n",
    "df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_imputed.iloc[:,1:]\n",
    "y=df_imputed.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3.0</td>\n",
       "      <td>26.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass   Age  SibSp  Parch     Fare  Sex_female  Sex_male\n",
       "0       3.0  22.0    1.0    0.0   7.2500         0.0       1.0\n",
       "1       1.0  38.0    1.0    0.0  71.2833         1.0       0.0\n",
       "2       3.0  26.0    0.0    0.0   7.9250         1.0       0.0\n",
       "3       1.0  35.0    1.0    0.0  53.1000         1.0       0.0\n",
       "4       3.0  35.0    0.0    0.0   8.0500         0.0       1.0\n",
       "..      ...   ...    ...    ...      ...         ...       ...\n",
       "886     2.0  27.0    0.0    0.0  13.0000         0.0       1.0\n",
       "887     1.0  19.0    0.0    0.0  30.0000         1.0       0.0\n",
       "888     3.0  26.8    1.0    2.0  23.4500         1.0       0.0\n",
       "889     1.0  26.0    0.0    0.0  30.0000         0.0       1.0\n",
       "890     3.0  32.0    0.0    0.0   7.7500         0.0       1.0\n",
       "\n",
       "[891 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.0\n",
       "1      1.0\n",
       "2      1.0\n",
       "3      1.0\n",
       "4      0.0\n",
       "      ... \n",
       "886    0.0\n",
       "887    1.0\n",
       "888    0.0\n",
       "889    1.0\n",
       "890    0.0\n",
       "Name: Survived, Length: 891, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_tensor(df):\n",
    "    return torch.from_numpy(df.values).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_to_tensor(X_train)\n",
    "X_test=df_to_tensor(X_test)\n",
    "y_train=df_to_tensor(y_train)\n",
    "y_test=df_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mineral(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mineral, self).__init__()\n",
    "        \n",
    "        self.hidden_linear1=nn.Linear(7, 30)\n",
    "        self.hidden_linear2=nn.Linear(30, 12)\n",
    "        self.hidden_linear3=nn.Linear(12, 8)\n",
    "        self.output_linear=nn.Linear(8, 1)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        out = torch.relu(self.hidden_linear1(input))\n",
    "        out = torch.relu(self.hidden_linear2(out))\n",
    "        out = torch.relu(self.hidden_linear3(out))\n",
    "        out = torch.sigmoid(self.output_linear(out))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mineral(\n",
       "  (hidden_linear1): Linear(in_features=7, out_features=30, bias=True)\n",
       "  (hidden_linear2): Linear(in_features=30, out_features=12, bias=True)\n",
       "  (hidden_linear3): Linear(in_features=12, out_features=8, bias=True)\n",
       "  (output_linear): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Mineral().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, delta=0.0, mode='min', verbose=True):\n",
    "        \"\"\"\n",
    "        patience (int): loss or score가 개선된 후 기다리는 기간. default: 3\n",
    "        delta  (float): 개선시 인정되는 최소 변화 수치. default: 0.0\n",
    "        mode     (str): 개선시 최소/최대값 기준 선정('min' or 'max'). default: 'min'.-- loss 가 min\n",
    "        verbose (bool): 메시지 출력. default: True\n",
    "        \"\"\"\n",
    "        self.early_stop = False\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        \n",
    "        self.best_score = np.Inf if mode == 'min' else 0\n",
    "        self.mode = mode\n",
    "        self.delta = delta\n",
    "        \n",
    "\n",
    "    def __call__(self, score):\n",
    "        \n",
    "        #__init__ 메서드는 클래스의 인스턴스를 초기화하기 위해 사용됩니다. 이는 새로운 객체, 즉 인스턴스를 생성할 때 호출되는 메서드입니다. 반면에,\n",
    "        #__call__ 메서드는 인스턴스를 함수처럼 호출 가능하게 만듭니다.\n",
    "        #기억해야 할 것은 __init__은 객체가 생성될 때 한 번 호출된다는 것입니다. 그러나 __call__은 인스턴스가 호출될 때마다 여러 번 호출될 수 있습니다.\n",
    "\n",
    "        if self.best_score is None: # X 왜냐면 infinity or 0\n",
    "            self.best_score = score\n",
    "            self.counter = 0 #patience counting \n",
    "        elif self.mode == 'min':\n",
    "            if score < (self.best_score - self.delta): #loss < infinity - 0\n",
    "                self.counter = 0\n",
    "                self.best_score = score\n",
    "                if self.verbose: #verbose= True\n",
    "                    print(f'[EarlyStopping] (Update) Best Score: {self.best_score:.5f}')\n",
    "            else: #loss 값이 작아지지 않을 경우\n",
    "                self.counter += 1 #patience 증가\n",
    "                # if self.verbose:\n",
    "                #     print(f'[EarlyStopping] (Patience) {self.counter}/{self.patience}, ' \\\n",
    "                #           f'Best: {self.best_score:.5f}' \\\n",
    "                #           f', Current: {score:.5f}, Delta: {np.abs(self.best_score - score):.5f}')\n",
    "                \n",
    "        elif self.mode == 'max': #accuracy 셀 때 max\n",
    "            if score > (self.best_score + self.delta): #loss < 0+ 0\n",
    "                self.counter = 0\n",
    "                self.best_score = score\n",
    "                if self.verbose:\n",
    "                    print(f'[EarlyStopping] (Update) Best Score: {self.best_score:.5f}')\n",
    "            else:\n",
    "                self.counter += 1\n",
    "                # if self.verbose:\n",
    "                #     print(f'[EarlyStopping] (Patience) {self.counter}/{self.patience}, ' \\\n",
    "                #           f'Best: {self.best_score:.5f}' \\\n",
    "                #           f', Current: {score:.5f}, Delta: {np.abs(self.best_score - score):.5f}')\n",
    "                \n",
    "            \n",
    "        if self.counter >= self.patience:\n",
    "            if self.verbose:\n",
    "                print(f'[EarlyStop Triggered] Best Score: {self.best_score:.5f}')\n",
    "            # Early Stop\n",
    "            self.early_stop = True\n",
    "        else:\n",
    "            # Continue\n",
    "            self.early_stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_validation(model, dataloader):\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, label in dataloader:\n",
    "            pred = model(data.to(device))\n",
    "            result = pred.squeeze(1).ge(torch.tensor(0.5).to(device))\n",
    "            correct += result.long().eq(label.to(device)).sum().item()\n",
    "    return (correct / len(dataloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 전체 저장\n",
    "torch.save(model.state_dict(), 'model/titanic.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_check_point(loss, model_path, boundary):\n",
    "    if loss.item() < boundary: #boundary: 이전 loss 값\n",
    "        torch.save( model.state_dict(), model_path) #state_dict 는 간단히 말해 각 계층을 매개변수 텐서로 매핑되는 Python 사전(dict) 객체 -- 가중치와 bias parameter\n",
    "        return loss.item()\n",
    "    else:\n",
    "        return boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping=EarlyStopping(patience=3, delta=0, mode='min', verbose=True) #default 값이니까 굳이 parameter 넣어주지 않아도 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EarlyStopping] (Update) Best Score: 0.71407\n",
      "[EarlyStopping] (Update) Best Score: 0.70122\n",
      "[EarlyStopping] (Update) Best Score: 0.68957\n",
      "[EarlyStopping] (Update) Best Score: 0.67930\n",
      "[EarlyStopping] (Update) Best Score: 0.67256\n",
      "[EarlyStopping] (Update) Best Score: 0.66683\n",
      "[EarlyStopping] (Update) Best Score: 0.66086\n",
      "[EarlyStopping] (Update) Best Score: 0.65498\n",
      "[EarlyStopping] (Update) Best Score: 0.64861\n",
      "[EarlyStopping] (Update) Best Score: 0.64133\n",
      "[EarlyStopping] (Update) Best Score: 0.63428\n",
      "[EarlyStopping] (Update) Best Score: 0.62721\n",
      "[EarlyStopping] (Update) Best Score: 0.62006\n",
      "[EarlyStopping] (Update) Best Score: 0.61327\n",
      "[EarlyStopping] (Update) Best Score: 0.60676\n",
      "[EarlyStopping] (Update) Best Score: 0.60090\n",
      "[EarlyStopping] (Update) Best Score: 0.59572\n",
      "[EarlyStopping] (Update) Best Score: 0.59115\n",
      "[EarlyStopping] (Update) Best Score: 0.58739\n",
      "[EarlyStopping] (Update) Best Score: 0.58395\n",
      "[EarlyStopping] (Update) Best Score: 0.58113\n",
      "[EarlyStopping] (Update) Best Score: 0.57898\n",
      "[EarlyStopping] (Update) Best Score: 0.57741\n",
      "[EarlyStopping] (Update) Best Score: 0.57598\n",
      "[EarlyStopping] (Update) Best Score: 0.57424\n",
      "[EarlyStopping] (Update) Best Score: 0.57228\n",
      "[EarlyStopping] (Update) Best Score: 0.57038\n",
      "[EarlyStopping] (Update) Best Score: 0.56856\n",
      "[EarlyStopping] (Update) Best Score: 0.56698\n",
      "[EarlyStopping] (Update) Best Score: 0.56547\n",
      "[EarlyStopping] (Update) Best Score: 0.56417\n",
      "[EarlyStopping] (Update) Best Score: 0.56280\n",
      "[EarlyStopping] (Update) Best Score: 0.56155\n",
      "[EarlyStopping] (Update) Best Score: 0.56019\n",
      "[EarlyStopping] (Update) Best Score: 0.55872\n",
      "[EarlyStopping] (Update) Best Score: 0.55732\n",
      "[EarlyStopping] (Update) Best Score: 0.55602\n",
      "[EarlyStopping] (Update) Best Score: 0.55457\n",
      "[EarlyStopping] (Update) Best Score: 0.55326\n",
      "[EarlyStopping] (Update) Best Score: 0.55204\n",
      "[EarlyStopping] (Update) Best Score: 0.55106\n",
      "[EarlyStopping] (Update) Best Score: 0.54999\n",
      "[EarlyStopping] (Update) Best Score: 0.54877\n",
      "[EarlyStopping] (Update) Best Score: 0.54777\n",
      "[EarlyStopping] (Update) Best Score: 0.54641\n",
      "[EarlyStopping] (Update) Best Score: 0.54536\n",
      "[EarlyStopping] (Update) Best Score: 0.54453\n",
      "[EarlyStopping] (Update) Best Score: 0.54357\n",
      "[EarlyStopping] (Update) Best Score: 0.54257\n",
      "[EarlyStopping] (Update) Best Score: 0.54124\n",
      "[EarlyStopping] (Update) Best Score: 0.54000\n",
      "[EarlyStopping] (Update) Best Score: 0.53892\n",
      "[EarlyStopping] (Update) Best Score: 0.53779\n",
      "[EarlyStopping] (Update) Best Score: 0.53660\n",
      "[EarlyStopping] (Update) Best Score: 0.53528\n",
      "[EarlyStopping] (Update) Best Score: 0.53402\n",
      "[EarlyStopping] (Update) Best Score: 0.53316\n",
      "[EarlyStopping] (Update) Best Score: 0.53203\n",
      "[EarlyStopping] (Update) Best Score: 0.53089\n",
      "[EarlyStopping] (Update) Best Score: 0.52959\n",
      "[EarlyStopping] (Update) Best Score: 0.52845\n",
      "[EarlyStopping] (Update) Best Score: 0.52215\n",
      "[EarlyStopping] (Update) Best Score: 0.52078\n",
      "[EarlyStopping] (Update) Best Score: 0.52032\n",
      "[EarlyStopping] (Update) Best Score: 0.51666\n",
      "[EarlyStopping] (Update) Best Score: 0.51580\n",
      "[EarlyStopping] (Update) Best Score: 0.51516\n",
      "[EarlyStopping] (Update) Best Score: 0.51193\n",
      "[EarlyStopping] (Update) Best Score: 0.50805\n",
      "[EarlyStopping] (Update) Best Score: 0.50602\n",
      "[EarlyStopping] (Update) Best Score: 0.50488\n",
      "[EarlyStopping] (Update) Best Score: 0.50281\n",
      "[EarlyStopping] (Update) Best Score: 0.49985\n",
      "[EarlyStopping] (Update) Best Score: 0.49752\n",
      "[EarlyStopping] (Update) Best Score: 0.49611\n",
      "[EarlyStopping] (Update) Best Score: 0.49428\n",
      "[EarlyStopping] (Update) Best Score: 0.49158\n",
      "[EarlyStopping] (Update) Best Score: 0.48912\n",
      "[EarlyStopping] (Update) Best Score: 0.48738\n",
      "[EarlyStopping] (Update) Best Score: 0.48539\n",
      "[EarlyStopping] (Update) Best Score: 0.48274\n",
      "[EarlyStopping] (Update) Best Score: 0.48005\n",
      "[EarlyStopping] (Update) Best Score: 0.47800\n",
      "[EarlyStopping] (Update) Best Score: 0.47619\n",
      "[EarlyStopping] (Update) Best Score: 0.47367\n",
      "[EarlyStopping] (Update) Best Score: 0.47095\n",
      "[EarlyStopping] (Update) Best Score: 0.46852\n",
      "[EarlyStopping] (Update) Best Score: 0.46625\n",
      "[EarlyStopping] (Update) Best Score: 0.46389\n",
      "[EarlyStopping] (Update) Best Score: 0.46131\n",
      "[EarlyStopping] (Update) Best Score: 0.45867\n",
      "[EarlyStopping] (Update) Best Score: 0.45656\n",
      "[EarlyStopping] (Update) Best Score: 0.45446\n",
      "[EarlyStopping] (Update) Best Score: 0.45211\n",
      "[EarlyStopping] (Update) Best Score: 0.44977\n",
      "[EarlyStopping] (Update) Best Score: 0.44779\n",
      "[EarlyStopping] (Update) Best Score: 0.44575\n",
      "[EarlyStopping] (Update) Best Score: 0.44342\n",
      "[EarlyStopping] (Update) Best Score: 0.44137\n",
      "[EarlyStopping] (Update) Best Score: 0.43929\n",
      "[EarlyStopping] (Update) Best Score: 0.43720\n",
      "[EarlyStopping] (Update) Best Score: 0.43498\n",
      "[EarlyStopping] (Update) Best Score: 0.43280\n",
      "[EarlyStopping] (Update) Best Score: 0.43081\n",
      "[EarlyStopping] (Update) Best Score: 0.42869\n",
      "[EarlyStopping] (Update) Best Score: 0.42657\n",
      "[EarlyStopping] (Update) Best Score: 0.42470\n",
      "[EarlyStopping] (Update) Best Score: 0.42289\n",
      "[EarlyStopping] (Update) Best Score: 0.42102\n",
      "[EarlyStopping] (Update) Best Score: 0.41907\n",
      "[EarlyStopping] (Update) Best Score: 0.41756\n",
      "[EarlyStopping] (Update) Best Score: 0.41560\n",
      "[EarlyStopping] (Update) Best Score: 0.41352\n",
      "[EarlyStopping] (Update) Best Score: 0.41206\n",
      "[EarlyStopping] (Update) Best Score: 0.41102\n",
      "[EarlyStopping] (Update) Best Score: 0.40940\n",
      "[EarlyStopping] (Update) Best Score: 0.40736\n",
      "[EarlyStopping] (Update) Best Score: 0.40599\n",
      "[EarlyStopping] (Update) Best Score: 0.40563\n",
      "[EarlyStopping] (Update) Best Score: 0.40352\n",
      "[EarlyStopping] (Update) Best Score: 0.40157\n",
      "[EarlyStopping] (Update) Best Score: 0.40023\n",
      "[EarlyStopping] (Update) Best Score: 0.39905\n",
      "[EarlyStopping] (Update) Best Score: 0.39799\n",
      "[EarlyStopping] (Update) Best Score: 0.39637\n",
      "[EarlyStopping] (Update) Best Score: 0.39480\n",
      "[EarlyStopping] (Update) Best Score: 0.39327\n",
      "[EarlyStopping] (Update) Best Score: 0.39252\n",
      "[EarlyStopping] (Update) Best Score: 0.39208\n",
      "[EarlyStopping] (Update) Best Score: 0.39061\n",
      "[EarlyStopping] (Update) Best Score: 0.38914\n",
      "[EarlyStopping] (Update) Best Score: 0.38813\n",
      "[EarlyStopping] (Update) Best Score: 0.38732\n",
      "[EarlyStopping] (Update) Best Score: 0.38720\n",
      "[EarlyStopping] (Update) Best Score: 0.38616\n",
      "[EarlyStopping] (Update) Best Score: 0.38470\n",
      "[EarlyStopping] (Update) Best Score: 0.38376\n",
      "[EarlyStopping] (Update) Best Score: 0.38350\n",
      "[EarlyStopping] (Update) Best Score: 0.38274\n",
      "[EarlyStopping] (Update) Best Score: 0.38186\n",
      "[EarlyStopping] (Update) Best Score: 0.38124\n",
      "[EarlyStopping] (Update) Best Score: 0.38092\n",
      "[EarlyStopping] (Update) Best Score: 0.38015\n",
      "[EarlyStopping] (Update) Best Score: 0.37873\n",
      "[EarlyStopping] (Update) Best Score: 0.37824\n",
      "[EarlyStopping] (Update) Best Score: 0.37788\n",
      "[EarlyStopping] (Update) Best Score: 0.37758\n",
      "[EarlyStopping] (Update) Best Score: 0.37644\n",
      "[EarlyStopping] (Update) Best Score: 0.37588\n",
      "[EarlyStopping] (Update) Best Score: 0.37560\n",
      "[EarlyStopping] (Update) Best Score: 0.37522\n",
      "[EarlyStopping] (Update) Best Score: 0.37396\n",
      "[EarlyStopping] (Update) Best Score: 0.37343\n",
      "[EarlyStopping] (Update) Best Score: 0.37316\n",
      "[EarlyStopping] (Update) Best Score: 0.37264\n",
      "[EarlyStopping] (Update) Best Score: 0.37241\n",
      "[EarlyStopping] (Update) Best Score: 0.37236\n",
      "[EarlyStopping] (Update) Best Score: 0.37187\n",
      "[EarlyStopping] (Update) Best Score: 0.37139\n",
      "[EarlyStopping] (Update) Best Score: 0.37123\n",
      "[EarlyStopping] (Update) Best Score: 0.37109\n",
      "[EarlyStopping] (Update) Best Score: 0.37035\n",
      "[EarlyStopping] (Update) Best Score: 0.37002\n",
      "[EarlyStopping] (Update) Best Score: 0.36937\n",
      "[EarlyStopping] (Update) Best Score: 0.36917\n",
      "[EarlyStopping] (Update) Best Score: 0.36904\n",
      "[EarlyStopping] (Update) Best Score: 0.36889\n",
      "[EarlyStopping] (Update) Best Score: 0.36874\n",
      "[EarlyStopping] (Update) Best Score: 0.36832\n",
      "[EarlyStopping] (Update) Best Score: 0.36778\n",
      "[EarlyStopping] (Update) Best Score: 0.36753\n",
      "[EarlyStopping] (Update) Best Score: 0.36728\n",
      "[EarlyStopping] (Update) Best Score: 0.36645\n",
      "[EarlyStopping] (Update) Best Score: 0.36641\n",
      "[EarlyStopping] (Update) Best Score: 0.36612\n",
      "[EarlyStopping] (Update) Best Score: 0.36574\n",
      "[EarlyStopping] (Update) Best Score: 0.36541\n",
      "[EarlyStopping] (Update) Best Score: 0.36531\n",
      "[EarlyStopping] (Update) Best Score: 0.36501\n",
      "[EarlyStopping] (Update) Best Score: 0.36491\n",
      "[EarlyStopping] (Update) Best Score: 0.36445\n",
      "[EarlyStopping] (Update) Best Score: 0.36407\n",
      "[EarlyStopping] (Update) Best Score: 0.36401\n",
      "[EarlyStopping] (Update) Best Score: 0.36342\n",
      "[EarlyStopping] (Update) Best Score: 0.36275\n",
      "[EarlyStopping] (Update) Best Score: 0.36262\n",
      "[EarlyStopping] (Update) Best Score: 0.36247\n",
      "[EarlyStopping] (Update) Best Score: 0.36193\n",
      "[EarlyStopping] (Update) Best Score: 0.36174\n",
      "[EarlyStopping] (Update) Best Score: 0.36161\n",
      "[EarlyStopping] (Update) Best Score: 0.36122\n",
      "[EarlyStopping] (Update) Best Score: 0.36074\n",
      "[EarlyStopping] (Update) Best Score: 0.36061\n",
      "[EarlyStopping] (Update) Best Score: 0.36004\n",
      "[EarlyStopping] (Update) Best Score: 0.35962\n",
      "[EarlyStopping] (Update) Best Score: 0.35957\n",
      "[EarlyStopping] (Update) Best Score: 0.35909\n",
      "[EarlyStopping] (Update) Best Score: 0.35852\n",
      "[EarlyStopping] (Update) Best Score: 0.35832\n",
      "[EarlyStopping] (Update) Best Score: 0.35820\n",
      "[EarlyStopping] (Update) Best Score: 0.35787\n",
      "[EarlyStopping] (Update) Best Score: 0.35779\n",
      "[EarlyStopping] (Update) Best Score: 0.35779\n",
      "[EarlyStopping] (Update) Best Score: 0.35728\n",
      "[EarlyStopping] (Update) Best Score: 0.35684\n",
      "[EarlyStop Triggered] Best Score: 0.35684\n"
     ]
    }
   ],
   "source": [
    "batch_size=300\n",
    "ds=TensorDataset(X_train, y_train)\n",
    "dataloader=DataLoader(ds, batch_size=batch_size)\n",
    "\n",
    "val_ds=TensorDataset(X_test, y_test)\n",
    "val_loader=DataLoader(val_ds)\n",
    "\n",
    "optimizer=optim.Adam(model.parameters())\n",
    "\n",
    "loss_fn=nn.BCELoss()\n",
    "\n",
    "n_epochs=2000\n",
    "loss=0.0\n",
    "\n",
    "save_loss=1.0\n",
    "\n",
    "list_accuracy=[]\n",
    "list_loss=[]\n",
    "\n",
    "for epoch in range(n_epochs+1):\n",
    "    model.train()\n",
    "    for data, label in dataloader:\n",
    "        #data = data.type(torch.FloatTensor)\n",
    "        out = model(data.to(device))\n",
    "        loss = loss_fn(out, label.unsqueeze(1).float().to(device))\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    accuracy = model_validation(model, val_loader)\n",
    "    \n",
    "    model_path = \"model/titanic.pth\"\n",
    "    \n",
    "    save_loss = model_check_point(loss, model_path, save_loss) #저장된 손실 return\n",
    "    \n",
    "    list_loss.append(loss.detach().cpu()) #loss가 gpu에 있을 때 cpu로 옮김 (.detach()) 역전파 사슬을 끊겠다 -- 끊은 상태에서만 옮겨짐 \n",
    "    list_accuracy.append(accuracy)\n",
    "    \n",
    "    #if epoch % 20 == 0:\n",
    "    #        print(f\"Epoch {epoch}, Training loss {loss:.4f},\")\n",
    "    #        print(\"Validation Accuracy: %f\" % accuracy)\n",
    "            \n",
    "    early_stopping(loss.item()) #__call__\n",
    "    if early_stopping.early_stop:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8101\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model/titanic.pth', map_location=device))\n",
    "test_ds=TensorDataset(X_test, y_test)\n",
    "test_loader=DataLoader(test_ds, batch_size=batch_size)\n",
    "\n",
    "correct=0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, label in test_loader:\n",
    "        pred=model(data.to(device))\n",
    "        result=pred.squeeze(1).ge(torch.tensor(0.5).to(device)) #1차원으로 변경, greater than equal, batch size 만큼의 TF\n",
    "        correct+=result.long().eq(label.to(device)).sum().item() #T=1, F=0\n",
    "        \n",
    "print(\"Accuracy: %.4f\" % (correct / len(test_loader.dataset)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p39-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
